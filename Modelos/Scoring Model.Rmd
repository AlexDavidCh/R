---
title: "Modelo de Otorgamiento de crédito"
author: "Alex Deiiv"
date: "1/8/2020"
output: rmdformats::readthedown
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

El scoring abarca una serie de técnicas estadísticas y es muy utilizado 
para otorgar o no crédito en las instituciones bancarias. Es un método que pronostica el riesgo futuro
por el incumplimiento de pagos en una ventana de tiempo determinada. Este procedimiento lleva
utilizándose desde hace 50 años gracias a los avances de los ordenadores que permiten trabajar con
grandes volúmenes de datos de manera rápida y eficaz. Estas técnicas tienen como objetivo asociar
una puntuación de riesgo a las solicitudes de crédito o a cuentas.

Para estre proyecto se  trabajara sobre una base de datos encontrada en un curso de estadística en la universidad de **Harvard**, La base se encuentra en un archivo de excel llamado **GermanCredit**. Esta base esta conformada por 31 variables y 1000 observaciones, cada observación corresponde a un formulario para otorgamiento de crédito.

# Minería de datos

**Lectura de Datos**
```{r}
library(readxl)
data <- read_excel("GermanCredit.xls")

knitr::kable(head(data,10), caption="Base de datos GERMAN.CREDIT")
```

## Data cleaning

#### Conjunto de Datos

Primero realizamos una limpieza de datos y consistencia de la data. Para lo cuál eliminamos la columna **OBS#** púes no aporta información para nuestros objetivos.

```{r}
library(dplyr)
data<-select(data,-c(`OBS#`))
```

### Missing Values

En la realidad es muy complicado tener una base de datos totalmente completa y consistente, para nuestro caso realizaremos un análisis de datos faltantes.

La librearía **naniar** nos brinda una colección de funciones óptimas para identificar datos faltantes.

**Datos faltantes globales**
```{r}
#Existen valores faltantes ?
library(naniar)
n_miss(data)
```
En este caso, no tenemos datos faltantes.

**Datos faltantes por variables**
```{r}
miss_var_summary(data)
miss_var_table(data)
```
De igual manera, no existen datos faltantes.

**Visualización de la proporción de datos faltantes por variables**
```{r}
vis_miss(data)
```

Una vez más, no tenemos datos faltantes.

### Imputación de Datos

Las técnicas de imputación de datos se aplica mediante réglas.

* Reglas:
  + Si existe más del $20\%$ de datos faltantes, las observaciones correspondientes a los datos faltantes son eliminados.
  + Si el porcentaje de datos faltantes es menor al $20\%$ se aplica una técnica de imputación.

* Técnicas de impmutación:
  + Media aritmética
  + Constante Global
  + Regresión
  + Regresión estocástica.

Dado que no tenemos datos faltantes, no es necesario realizar una imputación de datos.

## Discretización de datos

La discretización esta relacionada con la transformación de datos nominales a numéricos o viceversa.

**Variables Factor, numérico**
```{r}
data1<-data %>% mutate(RESPONSE=factor(RESPONSE, levels = c(0,1), labels = c("No","Si")),
                      FOREIGN=factor(FOREIGN,levels = c(0,1), labels = c("No","Si")),
                      TELEPHONE=factor(TELEPHONE,levels = c(0,1), labels = c("No","Si")),
                      NUM_DEPENDENTS=as.numeric(NUM_DEPENDENTS),
                      JOB=factor(JOB, levels = c(0,1,2,3), labels = c("Desempleado","No calificado","Calificado","Gerente-Autónomo")),
                      NUM_CREDITS=as.numeric(NUM_CREDITS),
                      OWN_RES=factor(OWN_RES,levels = c(0,1), labels = c("No","Si") ),
                      RENT=factor(RENT,levels = c(0,1), labels = c("No","Si") ),
                      OTHER_INSTALL=factor(OTHER_INSTALL,levels = c(0,1), labels = c("No","Si")),
                      AGE=as.numeric(AGE),
                      PROP_UNKN_NONE=factor(PROP_UNKN_NONE, levels=c(0,1),labels = c("No","Si")),
                      REAL_ESTATE=factor(REAL_ESTATE, levels = c(0,1), labels = c("No","Si")),
                      PRESENT_RESIDENT=factor(PRESENT_RESIDENT, levels= c(1,2,3,4),labels = c("0 a 1","1 a 2","2 a 3","mayor a 3")),
                      GUARANTOR=factor(GUARANTOR, levels = c(0,1), labels = c("No","Si")),
                      `CO-APPLICANT`=factor(`CO-APPLICANT`, levels = c(0,1), labels = c("No","Si")),
                      MALE_MAR_or_WID=factor(MALE_MAR_or_WID, levels = c(0,1), labels = c("No","Si")),
                      MALE_SINGLE=factor(MALE_SINGLE,levels = c(0,1), labels = c("No","Si")),
                      MALE_DIV=factor(MALE_DIV,levels = c(0,1), labels = c("No","Si")),
                      INSTALL_RATE=as.numeric(INSTALL_RATE),
                      EMPLOYMENT=factor(EMPLOYMENT, levels = c(0,1,2,3,4)),
                      SAV_ACCT=factor(SAV_ACCT),
                      AMOUNT=as.numeric(AMOUNT),
                      TYPE=as.factor(ifelse(RETRAINING==1,"RETRAINING",ifelse(EDUCATION==1,"EDUCATION",ifelse(`RADIO/TV`==1,"RADIO/TV",ifelse(FURNITURE==1,"FORNITURE",ifelse(USED_CAR==1,"USED.CAR","NEW.CAR")))))),
                      HISTORY=factor(HISTORY),
                      DURATION=as.numeric(DURATION),
                      CHK_ACCT=factor(CHK_ACCT,levels = c(0,1,2,3), labels = c( "0 DM","0 A 200DM","mayor a200"," No tiene")))

data1<-select(data1, -c("MALE_DIV", "MALE_SINGLE","MALE_MAR_or_WID","EDUCATION","RADIO/TV" ,"USED_CAR","NEW_CAR","FURNITURE","RETRAINING"))
Civil<-ifelse(data$MALE_DIV==1,"Male_div",ifelse(data$MALE_SINGLE,"M-single",ifelse(data$MALE_MAR_or_WID==1,"M.mar.wid","other")))
Civil<-as.factor(Civil)
data1<-data.frame(data1,Civil)

```

```{r}
knitr::kable(head(data1))
```


### Variables Cualitativas y cuantitativas

Análisis por variables, para ello las dividimos por tipo de variable.
```{r}
## Division de la data en tipo de variables
library(PCAmixdata)
corte<-splitmix(data1)
dquanti<-as.data.frame(corte$X.quanti)
dcuali<-as.data.frame(corte$X.quali)

```

**Variables Cualitativas**
Resumen por variable
```{r}
str(dcuali)
```

**Variables Cuantitativas**
Resumen por variable
```{r}
str(dquanti)
```


## Tratamiento de datos atípicos

Para obtener una base de datos consistente debemos realizar un tratamiento de datos atípicos, para eliminar u ajustar su influencia en los modelos.

### KNN

Algorítmo Knn. __(K Vecinos más cercanos)__

**Para el subconjunto de variables cuantitativas**

APlicamos el algoritmo knn con $K=5$. 

```{r}
library(FNN)
X<-get.knn(data = dquanti,k=5)
score<-rowMeans(X$nn.dist)
```

Tomamos el percentil $0.975$ para declarar como cota y obtenemos una lista de indices que superan la cota.

```{r}
cota<-quantile(score,c(0.75,0.975))[2]
index<-which(score>cota)
Out<-score[index]
length(Out)
```
Existen 25 valores detectados como atípicos.

```{r}
library(ggplot2)
valores<-as.factor(ifelse(score>cota,"Eliminar","No eliminar"))
obs<-c(1:length(score))
pd<-data.frame(score,valores,obs) 
ggplot(pd, aes(x=obs,y=score, col=valores)) +geom_point()
```

Por lo tanto, estos 25 datos deben ser separados del conjunto de datos para futuros análisis. Sin embargo, antes de eliminarlos vamos a realizar otro análisis mediante el algoritmo **Lof**.

### LOF

De igual manera procedemos a tomar un limite o cota para declarar atípicos a los datos que superen este límite.

```{r}
library(dbscan)
lof<-lof(as.data.frame(scale(dquanti)),5)
lim<-quantile(lof,c(0.75,0.975))[2]
indexout<-which(lof>lim)
length(lof[indexout])
```

Observamos que de igual manera tenemos 25 datos atípicos.

```{r}
library(ggplot2)
valores<-as.factor(ifelse(lof>lim,"Eliminar","No eliminar"))
obs<-c(1:length(lof))
pd<-data.frame(lof,valores,obs) 
ggplot(pd, aes(x=obs,y=lof, col=valores)) +geom_point()
```


Vemos que podrían ser más los datos atípicos, pero al análisar los dos algoritmos concluimos que es mejor tomar estos 25 y separarlos.

**ELIMINACIÓN DE DATOS ATÍPICOS**

```{r}
Datos<-data1
Datos<-Datos[-indexout,]
str(Datos)
```

Ahora, de aquí en adelante trabajaremos con el conjunto de datos **Datos*.

# Análisis descriptivo {.tabset .tabset-fade .tabset-pills}

El análisis previo para identificar el comportamiento y la relación de variables procedemos a realizar gráficos que nos pueda indicar alguna información relevante para nuestros estudios.

En principio tenemos $18$ variables cualitativas
```{r}
dcuali<-dcuali[-indexout,]
length(dcuali)
```

y $6$ variables cuantitativas. 

```{r}
dquanti<-dquanti[-indexout,]
length(dquanti)
```

## Análisis Univariante

**V. Cuantitativas**

```{r}
summary(dquanti)
```

Tenemos las siguientes observaciones:
  + La cantidad media de préstamo que es solicitado es de $2303,00\$$.
  + La duración media de los préstamos es $ 19 $ meses.
  + La edad promedio de los solicitantes a préstamo es de $35$ años.

```{r}
library(dplyr)
library(corrplot)
matriz<-cor(dquanti)
corrplot(matriz)
```

```{r}
library(dplyr)
library(tidyr)
data %>%
  select(AGE, AMOUNT,DURATION, INSTALL_RATE,NUM_CREDITS,NUM_DEPENDENTS) %>%
  gather(metric, value) %>%
  ggplot(aes(value, fill = metric)) +
  geom_density(show.legend = FALSE) +
  facet_wrap(~ metric, scales = "free")
```
 
**V. Cualitativas**

```{r}
summary(dcuali)
```

Tenemos las siguientes observaciones:

  + La mayor parte de solicitantes de crédito son recidentes locales
  + Un gran número de solicitantes tienen un trabajo entre calificado y no calificado.
  + El motivo de crédito es mayormente para la adquisisción de un vehívulo, la comra de electrodomesticos y muebles.

```{r}
p1 <- ggplot(data,aes(x=AGE,fill=RESPONSE))+
  geom_histogram()+
  labs(y="Apariciones",title="AGE")
p1

p2 <- ggplot(data,aes(x=AMOUNT,fill=RESPONSE))+
  geom_histogram()+
  labs(y="Apariciones",title="AGE")
p2


p3 <- ggplot(data1,aes(x=TYPE,fill=RESPONSE))+
  geom_bar()+
  labs(y="Apariciones",title="Fin de crédito")
p3

p4 <- ggplot(data1, aes(x=JOB, fill=RESPONSE))+
  geom_bar()+
  labs(y="Apariciones",title="Condición empleado")
p4

p5<-ggplot(data1, aes(x=CHK_ACCT, fill=RESPONSE))+
  geom_bar()+
  labs(y="Apariciones",title = "Cuenta en el banco")
p5
```

  
## Análisis Multivariante

Vamos a realizar algunos gráficos.

```{r}
library(ggplot2)
ggplot(dcuali, aes(x=TYPE,fill=TELEPHONE)) + geom_bar() + facet_wrap(~RESPONSE)
```
Podemos observar que el tipo para el cuál es solicitado el prestamo en alguna manera afecta, pues hay una gran cantidad de aceptación en los tipo: 

```{r}
ggplot(dcuali, aes(x=GUARANTOR,fill=GUARANTOR)) + geom_bar() + facet_wrap(~RESPONSE)
```

El tener garante, no afecta directamente a la desición de otorgar o no el crédito.

.
.


# Selección de variables {.tabset .tabset-fade .tabset-pills}

Para realizar un buen modelo, es necesario introducir las variables que tengan el mayor poder predictivo con respecto a la variable objetivo.

En nuestro caso, la variable objetivo es **RESPONSE** la cual es cualitativa.

## Valor de información IV

Muy tradicionalmente se ah conciderado el IV como una regla discriminatoria para el poder predictivo de las variables. Este IV tiene las siguientes reglas:

  +  IV < 0.2 : Sin poder predictivo.
  +  0.02 < IV < 0.1 : poder predictivo bajo
  +  0.1 < IV < 0.3 : poder predictivo medio
  +  0.3 < IV < 0.5 : poder predictivo fuerte
  +  IV > 0.5 : poder predictivo sospechosamente fuerte
  
```{r}
library(Information)
DatosIV<-Datos
DatosIV$RESPONSE<-as.numeric(DatosIV$RESPONSE)
DatosIV$RESPONSE<-ifelse(DatosIV$RESPONSE==1,0,1)
IV<- Information::create_infotables(data=DatosIV, y="RESPONSE", parallel = FALSE)
knitr::kable(head(IV$Summary))

```

En esta primera agrupación vemos que solo 6 variables tienen un poder predictivo conciderable para la aplicación de un modelo.
Talvez si se concidera otra agrupación en cada una de las variables podamos tener alguna otra variable con IV apropiado.


## Árboles de clasificación

Otra forma de realizar una selección de variables es utilizando los árboles de clasificación, ya que estos nos retornan los nodos principales para la clasificación.

```{r}
library(rpart)
library(rpart.plot)
arb <- rpart(RESPONSE ~.,data=Datos)
rpart.plot(arb)
```

Podemos ver las variables más importantes o más descriminatorias para  la clasificación

```{r}
arb$variable.importance
```

## Step wise, forward, backward

Este método de elección esta dado, una vez implementado el modelo.


# Partición de datos

Es necesario conciderar un subconjunto de los datos para entrenar nuestro modelo y otro subconjunto para testear el modelo.

Así, también se debe conciderar dicha partición de manera que los datos sean balanceados en ambos subsets. **Conjunto de datos de entrenamiento y test**


```{r}
library(rsample)
set.seed(123)
corte<- initial_split(Datos, prop = 0.7, strata = "RESPONSE")
train <- training(corte)
test  <- testing(corte)

table(train$RESPONSE) %>% prop.table()
table(test$RESPONSE) %>% prop.table()

```


Claramente vemos que los datos estan desbalanceados.

## Balanceo de Datos

Se puede ver más sobre balanceo de datos Aqui [Link](https://rpubs.com/subasish/578582 "Balanceo")
```{r}
library(ROSE)
Dtrain<-train
Dtrain <- ovun.sample(RESPONSE ~ ., data = Dtrain, method = "both", p=0.5, N=700, seed = 1)$data
table(Dtrain$RESPONSE) %>% prop.table()
```

Ahora vemos que ambas clases tienen casi la misma proporcion.

# Modelos de Regresión Logística {.tabset .tabset-fade .tabset-pills}


## Modelo 1

Para el primer modelo consideraremos todas las variables y los datos balanceados.

```{r}
library(glm2)
model1<-glm(RESPONSE ~. , family = binomial , data= Dtrain)
```

Vemos que 16 variables son significativas para el modelo y tenemos:

  + AIC = $656.61$
  + Null deviance = $969.83$

### Matriz de confución

```{r}
library(caret)
y_fit<-predict(model1,newdata = Dtrain, type="response")
y_fit<-as.factor(ifelse(y_fit>0.5,"Si","No"))

confusionMatrix(Dtrain$RESPONSE,y_fit)
```

Muy por debajo de lo esperado, una presición muy inferior y que decir de la sensibilidad y especificidad.

En primera instancia se sospecha que no se debe balancear los datos.

## Modelo 2

Para el segundo modelo consideraremos todas las variables y los datos sin balancear.

```{r}
model2<-glm(RESPONSE~., family = binomial(),data=train)
summary(model2)
```

Vemos que 16 variables son significativas para el modelo y tenemos:

  + AIC = $686.51$
  + Null deviance = $837.01$

### Matriz de confunción

```{r}
y2_fit<-as.factor(ifelse(model2$fitted.values>0.5,"Si","No"))
confusionMatrix(train$RESPONSE,y2_fit)
```

Ahora si, podemos ver que tenemos una presición del $80.26%$, y una sensibilidad, especificidad con un comportamiento muy estable.


### Predicciones

```{r}
y_pred<-predict(model2, newdata = test , type="response")
y_pred<- as.factor(ifelse(y_pred>0.5,"Si","No"))
confusionMatrix(test$RESPONSE,y_pred)
```
Con los datos de test vemos que tenemos una caída de la presición de  $80.26%$  a $73.2%$ y la sensibilidad y especificidad se ve un poco deteriorada.

## Modelo 3

Para el modelo 3, concideraremos las variables más importantes obtenidas por el árbol de clasificación y con los datos sin balancear.


```{r}
model3<-glm(RESPONSE ~ CHK_ACCT + DURATION + AMOUNT +  HISTORY + TYPE + SAV_ACCT +  AGE 
                        + PRESENT_RESIDENT + PROP_UNKN_NONE + EMPLOYMENT + JOB + INSTALL_RATE
                        + GUARANTOR + FOREIGN, data=train , family = binomial())
summary(model3)
```
  
  + AIC = $692.61$
  + Null deviance = $837.01$

### Matriz de confusion

```{r}
y3_fit<-as.factor(ifelse(model3$fitted.values>0.45,"Si","No"))
confusionMatrix(train$RESPONSE,y3_fit)
```

Tenemos una presición de $78.22%$ no supera al modelo 2. La sensibilidd se mantiene en buen comportamiento con la especificidad.

### Predicciones

```{r}
y_pred<-predict(model3, newdata = test , type="response")
y_pred<- as.factor(ifelse(y_pred>0.5,"Si","No"))
confusionMatrix(test$RESPONSE,y_pred)
```

Podemos ver que la presición en el conjunto de datos test no cambia mucho en relación con los datos train, y la sensibilidad empieza a verse un poco afectada en contraste con la especificidad.

# Bondad de Ajuste {.tabset .tabset-fade .tabset-pills}


## Curvas ROC


**Modelo 2**

```{r}
library(InformationValue)
plotROC(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model2$fitted.values)

```


**MOdelo 3**

```{r}
plotROC(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model3$fitted.values)
```


## Ks y Ks-PLOT

**Modelo 2**

Para estudiar la eficacia del modelo podemos también análisar el estadístico Ks de Kolmogorov:
  + un Ks < 0.2 la eficacia es baja
  + 0.2< ks <0.7 : buena eficacia 
  + ks> 0.7 : puede existir un sobreajuste
  
```{r}
ks_stat(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model2$fitted.values)
ks_plot(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model2$fitted.values)
```


**Modelo 3**
```{r}
ks_stat(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model3$fitted.values)
ks_plot(as.numeric(ifelse(train$RESPONSE=="Si",1,0)),model3$fitted.values)
```


## Índice de Gini
 
 El Índice de gini viende dado por: $Gini= 2*AUC -1 $.
 
 **Modelo 2**
```{r}

```
 
**Modelo 3**
```{r}

```
 
## R-cuadrado

**Modelo 2**
```{r}
# Opcion 2
library(sigr)
R2 <- wrapChiSqTest(model2)
R2$pseudoR2
```

**Modelo 3**
```{r}
# Opcion 2
library(sigr)
R2 <- wrapChiSqTest(model3)
R2$pseudoR2
```

## Deviance

**Modelo 2**
```{r}
library(broom)
# Opcion 1
broom::glance(model2) %>%
  summarize(deviance)
```

**Modelo 3**
```{r}
library(broom)
# Opcion 1
broom::glance(model3) %>%
  summarize( deviance)
```


# Teoría de Desición

## NUEVOS CLIENTES

## Datos Solicitantes

## Probabilidad de Default

## Matriz P 
